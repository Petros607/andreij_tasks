import logging
import requests
from aiogram import Bot, Dispatcher, types
from aiogram.enums.parse_mode import ParseMode
from aiogram.types import Message
from aiogram.utils import executor
from dotenv import load_dotenv
import os

load_dotenv()

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "llama3")
OLLAMA_API_URL = os.getenv("OLLAMA_API_URL", "http://localhost:11434/api/generate")

logging.basicConfig(level=logging.INFO)
bot = Bot(token=TELEGRAM_TOKEN, parse_mode=ParseMode.HTML)
dp = Dispatcher(bot)

def query_llama(prompt: str) -> str:
    try:
        response = requests.post(
            OLLAMA_API_URL,
            json={"model": OLLAMA_MODEL, "prompt": prompt, "stream": False}
        )
        if response.status_code == 200:
            return response.json()['response'].strip()
        else:
            return "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ LLaMA: " + response.text
    except Exception as e:
        return f"–û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å Ollama: {e}"

@dp.message_handler(commands=['start'])
async def handle_start(message: Message):
    welcome_text = (
        "–ü—Ä–∏–≤–µ—Ç! –Ø ‚Äî Telegram-–±–æ—Ç, –ø–æ–¥–∫–ª—é—á—ë–Ω–Ω—ã–π –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏ LLaMA 3 ü¶ô\n\n"
        "–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ –º–Ω–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –∏ —è –ø–æ—Å—Ç–∞—Ä–∞—é—Å—å –æ—Ç–≤–µ—Ç–∏—Ç—å.\n"
        "–í –ª—é–±–æ–π –º–æ–º–µ–Ω—Ç —Ç—ã –º–æ–∂–µ—à—å –≤–≤–µ—Å—Ç–∏ /start, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –¥–∏–∞–ª–æ–≥ –∑–∞–Ω–æ–≤–æ."
    )
    await message.answer(welcome_text)

@dp.message_handler()
async def handle_message(message: Message):
    if message.text:
        user_text = message.text.strip()
        if user_text:
            await message.answer("ü§ñ –î—É–º–∞—é...")
            response = query_llama(user_text)
            await message.answer(response)
    else:
        await message.answer("–Ø –ø–æ–Ω–∏–º–∞—é —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è.")

if __name__ == '__main__':
    print("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω!")
    executor.start_polling(dp, skip_updates=True)
